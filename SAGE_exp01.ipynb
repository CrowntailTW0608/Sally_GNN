{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327344d3-dde4-4160-b05a-1b85d8c8aac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime \n",
    "import glob\n",
    "pd.set_option('display.max_rows', 110)\n",
    "\n",
    "\n",
    "import dgl\n",
    "from dgl.data import DGLDataset\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.utils import dense_to_sparse, to_dense_adj\n",
    "from scipy.spatial import distance\n",
    "# Contruct a two-layer GNN model\n",
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8297b83c-e483-4bc2-9d5d-6ed7fa49682f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download dataset from : https://data.epa.gov.tw/dataset/aqx_p_488\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# for r,ds,fs in os.walk(r'C:\\Users\\crown\\OneDrive\\桌面\\新增資料夾\\2021\\aqx_p_488_2021-07'):\n",
    "#     fs = [f for f in fs if f.endswith('.csv')]\n",
    "#     for f in fs:\n",
    "#         p = os.path.join(r,f)\n",
    "#         print(p)\n",
    "        \n",
    "#         df_tmp = pd.read_csv(p)\n",
    "        \n",
    "#         df = df.append(df_tmp)\n",
    "        \n",
    "#         del df_tmp\n",
    "        \n",
    "# df.to_csv(r'./data/df_2021_07.csv',index=False,encoding='ansi')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "80aa6e45-1604-41a6-85d0-0981add09ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PM25Dataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='PM25')\n",
    "\n",
    "    def process(self):\n",
    "        \n",
    "        df = self.gen_df()\n",
    "        self.nodes_data = df\n",
    "        col_features=[ 'SO2', 'CO', 'O3', 'O3_8hr', 'PM10', 'NO2', 'NOx', 'NO', 'WindSpeed', 'WindDirec', 'CO_8hr', 'PM2.5_AVG', 'PM10_AVG', 'SO2_AVG']\n",
    "        node_features = torch.from_numpy(df[col_features].to_numpy())\n",
    "        node_features = (node_features-node_features.mean(axis=(0,1)))/node_features.std(axis=(0,1))\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float32)\n",
    "        node_labels = torch.from_numpy(df[['PM2.5']].to_numpy())\n",
    "        node_labels = torch.tensor(node_labels, dtype=torch.float32)\n",
    "        \n",
    "        edge_index, dist = self.gen_edge()\n",
    "        \n",
    "        edge_features = torch.from_numpy(dist)\n",
    "        edges_src = torch.from_numpy(edge_index[0])\n",
    "        edges_dst = torch.from_numpy(edge_index[1])\n",
    "\n",
    "        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=self.nodes_data.shape[0])\n",
    "        self.graph.ndata['feat'] = node_features\n",
    "        self.graph.ndata['label'] = node_labels\n",
    "        self.graph.edata['weight'] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = self.nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train:n_train + n_val] = True\n",
    "        test_mask[n_train + n_val:] = True\n",
    "        self.graph.ndata['train_mask'] = train_mask\n",
    "        self.graph.ndata['val_mask'] = val_mask\n",
    "        self.graph.ndata['test_mask'] = test_mask\n",
    "\n",
    "    def gen_df(self):\n",
    "        df = pd.read_csv(r'./data/df_2021_07.csv',encoding='ansi')\n",
    "        df = df[['SO2', 'CO', 'O3', 'O3_8hr', 'PM10', 'NO2', 'NOx', 'NO', 'WindSpeed', 'WindDirec', 'CO_8hr', 'PM2.5_AVG', 'PM10_AVG', 'SO2_AVG','PM2.5','Longitude','Latitude']]\n",
    "        \n",
    "        df = df.replace({'-':0}).astype(float).dropna()\n",
    "        df[['Longitude','Latitude']] = df[['Longitude','Latitude']].apply(lambda x:round(x,5))\n",
    "\n",
    "        from sklearn.utils import shuffle\n",
    "        df = shuffle(df)\n",
    "        return df\n",
    "    \n",
    "    def gen_edge(self):\n",
    "        \n",
    "        node_num = self.nodes_data.shape[0]\n",
    "        coords = []\n",
    "        for i,r in self.nodes_data.iterrows():\n",
    "            coords.append([r['Longitude'], r['Latitude']])\n",
    "\n",
    "        dist = distance.cdist(coords, coords, 'euclidean')\n",
    "        adj = np.zeros((node_num, node_num), dtype=np.uint8)\n",
    "        adj[dist <= 0.4] = 1\n",
    "        assert adj.shape == dist.shape\n",
    "        dist = dist * adj #\n",
    "        edge_index, dist = dense_to_sparse(torch.tensor(dist)) # convert to spare tensor\n",
    "        edge_index, dist = edge_index.numpy(), dist.numpy()\n",
    "\n",
    "        return edge_index, dist\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "ef76e265-81f7-41c1-bb64-24ddcc1daecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crown\\.conda\\envs\\yp37_pytorch170_GNN\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\crown\\.conda\\envs\\yp37_pytorch170_GNN\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=28607, num_edges=138648656,\n",
      "      ndata_schemes={'feat': Scheme(shape=(14,), dtype=torch.float32), 'label': Scheme(shape=(1,), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n"
     ]
    }
   ],
   "source": [
    "dataset = PM25Dataset()\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5a9a2d8a-a0af-4b7d-83d2-17f6382cde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.SAGEConv( in_feats=in_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "        self.conv2 = dglnn.SAGEConv( in_feats=hid_feats, out_feats=hid_feats, aggregator_type='mean')\n",
    "        self.conv3 = dglnn.SAGEConv( in_feats=hid_feats, out_feats=out_feats, aggregator_type='mean')\n",
    "        self.linear1 = nn.Linear(55,1)\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(graph, h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv3(graph, h)\n",
    "        h = self.linear1(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e181f965-cb63-42d2-939d-cf90ceaac73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = graph.ndata['feat']\n",
    "node_labels = graph.ndata['label']\n",
    "train_mask = graph.ndata['train_mask']\n",
    "valid_mask = graph.ndata['val_mask']\n",
    "test_mask = graph.ndata['test_mask']\n",
    "n_features = node_features.shape[1]\n",
    "n_labels = int(node_labels.max().item() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6aa3e792-fa6c-4fa2-a6fe-1e12221843b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, graph, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        loss = F.mse_loss(logits, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "fed55f33-1a2d-433d-aa4c-39c00ef3b4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = SAGE(in_feats=n_features, hid_feats=100, out_feats=n_labels)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "train_losses,val_losses = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "784d015d-4cca-4851-b083-38b34e137f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0, train loss:14.5859 val loss15.1704\n",
      "#1, train loss:14.4353 val loss15.0125\n",
      "#2, train loss:14.2896 val loss14.8620\n",
      "#3, train loss:14.1509 val loss14.7222\n",
      "#4, train loss:14.0236 val loss14.5903\n",
      "#5, train loss:13.9074 val loss14.4642\n",
      "#6, train loss:13.7986 val loss14.3438\n",
      "#7, train loss:13.6940 val loss14.2282\n",
      "#8, train loss:13.5913 val loss14.1167\n",
      "#9, train loss:13.4886 val loss14.0062\n",
      "#10, train loss:13.3868 val loss13.8938\n",
      "#11, train loss:13.2847 val loss13.7802\n",
      "#12, train loss:13.1833 val loss13.6685\n",
      "#13, train loss:13.0823 val loss13.5586\n",
      "#14, train loss:12.9812 val loss13.4506\n",
      "#15, train loss:12.8808 val loss13.3452\n",
      "#16, train loss:12.7822 val loss13.2427\n",
      "#17, train loss:12.6870 val loss13.1446\n",
      "#18, train loss:12.5959 val loss13.0532\n",
      "#19, train loss:12.5096 val loss12.9677\n",
      "#20, train loss:12.4285 val loss12.8869\n",
      "#21, train loss:12.3520 val loss12.8106\n",
      "#22, train loss:12.2797 val loss12.7387\n",
      "#23, train loss:12.2108 val loss12.6697\n",
      "#24, train loss:12.1451 val loss12.6015\n",
      "#25, train loss:12.0818 val loss12.5350\n",
      "#26, train loss:12.0207 val loss12.4715\n",
      "#27, train loss:11.9613 val loss12.4097\n",
      "#28, train loss:11.9038 val loss12.3481\n",
      "#29, train loss:11.8476 val loss12.2882\n",
      "#30, train loss:11.7929 val loss12.2305\n",
      "#31, train loss:11.7397 val loss12.1738\n",
      "#32, train loss:11.6879 val loss12.1186\n",
      "#33, train loss:11.6375 val loss12.0663\n",
      "#34, train loss:11.5884 val loss12.0148\n",
      "#35, train loss:11.5403 val loss11.9650\n",
      "#36, train loss:11.4931 val loss11.9180\n",
      "#37, train loss:11.4467 val loss11.8716\n",
      "#38, train loss:11.4011 val loss11.8274\n",
      "#39, train loss:11.3561 val loss11.7840\n",
      "#40, train loss:11.3115 val loss11.7406\n",
      "#41, train loss:11.2672 val loss11.6992\n",
      "#42, train loss:11.2233 val loss11.6563\n",
      "#43, train loss:11.1796 val loss11.6158\n",
      "#44, train loss:11.1361 val loss11.5733\n",
      "#45, train loss:11.0927 val loss11.5333\n",
      "#46, train loss:11.0493 val loss11.4907\n",
      "#47, train loss:11.0059 val loss11.4518\n",
      "#48, train loss:10.9628 val loss11.4089\n",
      "#49, train loss:10.9198 val loss11.3716\n",
      "#50, train loss:10.8768 val loss11.3280\n",
      "#51, train loss:10.8339 val loss11.2913\n",
      "#52, train loss:10.7912 val loss11.2482\n",
      "#53, train loss:10.7484 val loss11.2101\n",
      "#54, train loss:10.7057 val loss11.1687\n",
      "#55, train loss:10.6630 val loss11.1283\n",
      "#56, train loss:10.6203 val loss11.0885\n",
      "#57, train loss:10.5778 val loss11.0465\n",
      "#58, train loss:10.5354 val loss11.0088\n",
      "#59, train loss:10.4930 val loss10.9655\n",
      "#60, train loss:10.4506 val loss10.9301\n",
      "#61, train loss:10.4085 val loss10.8854\n",
      "#62, train loss:10.3666 val loss10.8522\n",
      "#63, train loss:10.3247 val loss10.8065\n",
      "#64, train loss:10.2826 val loss10.7725\n",
      "#65, train loss:10.2404 val loss10.7286\n",
      "#66, train loss:10.1980 val loss10.6904\n",
      "#67, train loss:10.1557 val loss10.6514\n",
      "#68, train loss:10.1136 val loss10.6090\n",
      "#69, train loss:10.0715 val loss10.5737\n",
      "#70, train loss:10.0294 val loss10.5277\n",
      "#71, train loss:9.9874 val loss10.4948\n",
      "#72, train loss:9.9453 val loss10.4459\n",
      "#73, train loss:9.9030 val loss10.4134\n",
      "#74, train loss:9.8603 val loss10.3640\n",
      "#75, train loss:9.8170 val loss10.3276\n",
      "#76, train loss:9.7735 val loss10.2827\n",
      "#77, train loss:9.7301 val loss10.2414\n",
      "#78, train loss:9.6870 val loss10.2027\n",
      "#79, train loss:9.6441 val loss10.1565\n",
      "#80, train loss:9.6012 val loss10.1225\n",
      "#81, train loss:9.5584 val loss10.0719\n",
      "#82, train loss:9.5157 val loss10.0429\n",
      "#83, train loss:9.4729 val loss9.9877\n",
      "#84, train loss:9.4300 val loss9.9592\n",
      "#85, train loss:9.3860 val loss9.9027\n",
      "#86, train loss:9.3405 val loss9.8661\n",
      "#87, train loss:9.2947 val loss9.8205\n",
      "#88, train loss:9.2496 val loss9.7742\n",
      "#89, train loss:9.2052 val loss9.7403\n",
      "#90, train loss:9.1610 val loss9.6849\n",
      "#91, train loss:9.1162 val loss9.6551\n",
      "#92, train loss:9.0701 val loss9.5947\n",
      "#93, train loss:9.0215 val loss9.5598\n",
      "#94, train loss:8.9714 val loss9.5008\n",
      "#95, train loss:8.9200 val loss9.4580\n",
      "#96, train loss:8.8689 val loss9.4107\n",
      "#97, train loss:8.8198 val loss9.3624\n",
      "#98, train loss:8.7708 val loss9.3249\n",
      "#99, train loss:8.7231 val loss9.2693\n",
      "test loss : {} 8.489045143127441\n"
     ]
    }
   ],
   "source": [
    "early_stop = 10\n",
    "min_val_loss = 999999\n",
    "min_val_epoch = 0\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    # forward propagation by using all nodes\n",
    "    logits = model(graph, node_features)\n",
    "    # compute loss\n",
    "    train_loss = F.mse_loss(logits[train_mask], node_labels[train_mask])\n",
    "    # backward propagation\n",
    "    opt.zero_grad()\n",
    "    train_loss.backward()\n",
    "    opt.step()\n",
    "    train_losses.append(train_loss.item())\n",
    "    \n",
    "    val_loss = evaluate(model, graph, node_features, node_labels, valid_mask)\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "    print('#{}, train loss:{:.4f} val loss{:.4f}'.format(epoch,train_loss.item(),val_loss.item()),end='')\n",
    "    \n",
    "    if val_loss.item() < min_val_loss:\n",
    "        min_val_loss = val_loss.item()\n",
    "        min_val_epoch = epoch\n",
    "    else:\n",
    "        print(' no improve...',end='')\n",
    "        \n",
    "    if epoch >= min_val_epoch + early_stop :\n",
    "        print(' early stop...')\n",
    "        break\n",
    "        \n",
    "\n",
    "    print()\n",
    "    # Save model if necessary.  Omitted in this example.\n",
    "    \n",
    "test_loss = evaluate(model, graph, node_features, node_labels, test_mask)\n",
    "print('test loss : {}',test_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d55e87fc-9bd5-46cb-b8a4-09e17b34426f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11f1d9cfd48>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses,label='train')\n",
    "plt.plot(val_losses,label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ded338-d703-4153-91b2-1eed5978488f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
